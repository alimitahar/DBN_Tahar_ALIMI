{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "class DBN:\n",
    "    def __init__(self, n_v, layers, k=1, mean_field=True):\n",
    "        \n",
    "        if n_v is None or layers is None: raise ValueError(\"Incorrect inputs for layer 0.\")\n",
    "        \n",
    "        n_hs = [n_v]        \n",
    "        n_layer = 0\n",
    "        training_done = True\n",
    "        rbms = []\n",
    "        for (n_h, model) in layers:\n",
    "            n_layer += 1\n",
    "            if model is None:\n",
    "                if n_h <= 0: raise ValueError(\"Incorrect inputs for layer %d\" % (n_layer))\n",
    "                else: n_hs.append(n_h)\n",
    "\n",
    "                rbm = RBM(n_hs[n_layer-1], n_h, k=k)\n",
    "                training_done = False\n",
    "\n",
    "            else:\n",
    "                assert training_done\n",
    "                \n",
    "                rbm = RBM.load_model(model)\n",
    "                assert rbm.n_v == n_hs[n_layer-1]                \n",
    "                n_hs.append(rbm.n_h)\n",
    "\n",
    "            rbms.append(rbm)\n",
    "\n",
    "        self.n_hs = n_hs\n",
    "        self.n_layer = n_layer\n",
    "        self.training_done = training_done\n",
    "        self.rbms = rbms\n",
    "        self.mean_field = mean_field\n",
    "        return\n",
    "    \n",
    "    def forward(self, X):\n",
    "        assert self.training_done\n",
    "        \n",
    "        Hp = X\n",
    "        for i in range(self.n_layer):\n",
    "            Hp, Hs = self.rbms[i].forward(Hp)\n",
    "        \n",
    "        return Hp, Hs\n",
    "\n",
    "    def backward(self, H):\n",
    "        assert self.training_done\n",
    "\n",
    "        Vp = H\n",
    "        for i in reversed(range(self.n_layer)):\n",
    "            Vp, Vs = self.rbms[i].backward(Vp)\n",
    "        \n",
    "        return Vp, Vs\n",
    "\n",
    "    def train_1layer_1batch(self, V, layer):\n",
    "        Hp = V\n",
    "        for i in range(layer):\n",
    "            Hp, Hs = self.rbms[i].forward(Hp)\n",
    "        \n",
    "        if self.mean_field or layer==0: \n",
    "            self.rbms[layer].contrastive_divergence(Hp, self.learning)\n",
    "        else:\n",
    "            for j in range(5):\n",
    "                Vs = np.random.binomial(1, Hp, size=Hp.shape)\n",
    "                self.rbms[layer].contrastive_divergence(Vs, self.learning)\n",
    "                \n",
    "        return\n",
    "\n",
    "    def train_1layer(self, X, layer, epochs, batch_size=10, learning=0.01, save_file=None):\n",
    "        assert not self.rbms[layer].training_done\n",
    "        \n",
    "        self.learning = learning\n",
    "        n_x = X.shape[0]\n",
    "        n_batch = n_x//batch_size\n",
    "        startrate = learning\n",
    "        for e in range(epochs):\n",
    "            learning = startrate * math.pow(0.1, e//50) \n",
    "            for i in range(n_batch):\n",
    "                s = i*batch_size\n",
    "                V = X[s:s+batch_size]\n",
    "                self.train_1layer_1batch(V, layer)\n",
    "\n",
    "        self.rbms[layer].save_model(save_file+\"-\"+str(layer+1)+\".epochs\"+str(epochs))\n",
    "        self.rbms[layer].training_done = True\n",
    "        return\n",
    "    \n",
    "    # this is internal API for more complex network to use\n",
    "    def train_model(self, X, epochs=1, batch_size=10, learning=0.01, save_file=None):\n",
    "        \n",
    "        for layer in range(self.n_layer):\n",
    "            if self.rbms[layer].training_done: continue\n",
    "            self.train_1layer(X, layer, epochs, batch_size, learning, save_file)\n",
    "        \n",
    "        return\n",
    "\n",
    "    # this is the API for app to use\n",
    "    def train(self, X, epochs=1, batch_size=10, learning=0.01, save_file=None):\n",
    "        if self.training_done: return\n",
    "        \n",
    "        save_file += \".dbn.layer\" + str(self.n_layer)\n",
    "        self.train_model(X, epochs, batch_size, learning, save_file)\n",
    "        \n",
    "        self.training_done = True\n",
    "        return\n",
    "    \n",
    "    def reconstruct(self, X):\n",
    "        h_layer = self.n_layer - 1\n",
    "        Hp = X\n",
    "        for i in range(h_layer):\n",
    "            Hp, Hs = self.rbms[i].forward(Hp)\n",
    "        \n",
    "        Vp, Vs = self.rbms[h_layer].reconstruct(Hp)\n",
    "\n",
    "        for i in reversed(range(h_layer)):\n",
    "            Hp, Hs = self.rbms[i].backward(Hp)\n",
    "\n",
    "        return Hp, Hs\n",
    "    \n",
    "    def show_features(self, shapes, title, count=-1):\n",
    "        \n",
    "        #for i in range(self.n_layer):\n",
    "        #    rbm = self.rbms[i]\n",
    "        #    rbm.show_features(shapes[i], \"MNIST learned features in DBN layer %d\" % (i+1), count)\n",
    "\n",
    "        lower_rbm = None\n",
    "        for i in range(self.n_layer):\n",
    "            rbm = self.rbms[i]\n",
    "            if i!=0:\n",
    "                W = np.dot(rbm.W, lower_rbm.W)\n",
    "                rbm = RBM(W.shape[1], W.shape[0], W=W)\n",
    "               \n",
    "            rbm.show_features(shapes[0], title +\" learned features in layer %d\" % (i+1), count)\n",
    "            lower_rbm = rbm\n",
    "\n",
    "        return lower_rbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class MNIST_DBN:\n",
    "    \n",
    "    def __init__(self, n_v, layers, data_path): \n",
    "        self.dbn = DBN(n_v, layers)\n",
    "        \n",
    "        self.train_input = MnistInput(\"train\", data_path)\n",
    "        self.test_input = MnistInput(\"test\", data_path)\n",
    "        return\n",
    "\n",
    "    def train(self, train_size=-1, n_epoch=1, batch_size=10, learning=0.01):\n",
    "        X = []\n",
    "        n_x = 0\n",
    "        for x, y in self.train_input.read(train_size):\n",
    "            X.append(x)\n",
    "            n_x += 1\n",
    "\n",
    "        X = np.array(X).reshape(n_x, -1) > 30\n",
    "        X = X*1\n",
    "        \n",
    "        self.dbn.train(X, n_epoch, batch_size, learning, save_file=\"mnist\")\n",
    "        return\n",
    "    \n",
    "    def test_reconstruct(self, n):\n",
    "        X=[]; i=2*n\n",
    "        for x, y in self.test_input.read(n):\n",
    "            x *= np.random.binomial(1, i/(n*2), size=(28,28))\n",
    "            x = x * 2*n/i\n",
    "            X.append(x)\n",
    "            i -=1\n",
    "\n",
    "        ncols = 10\n",
    "        nrows = int(n/5)\n",
    "        fig = plt.figure(figsize=(ncols, nrows), dpi=300)\n",
    "        grid = Grid(fig, rect=111, nrows_ncols=(nrows,10))\n",
    "\n",
    "        for i, ax in enumerate(grid):\n",
    "            j = i//2\n",
    "            if i%2 == 0:\n",
    "                ax.imshow(X[j].reshape(28,28), cmap=mpl.cm.Greys)\n",
    "                if i<ncols:\n",
    "                    ax.set_title(\"Original\")\n",
    "            else:\n",
    "                Vp, Vs = self.dbn.reconstruct(X[j].reshape(1, -1)/255)\n",
    "                ax.imshow(Vp.reshape(28,28), cmap=mpl.cm.Greys)\n",
    "                if i<ncols:\n",
    "                    ax.set_title(\"Reconst.\")\n",
    "\n",
    "            ax.set_axis_off()\n",
    "\n",
    "        fig.suptitle('Original and reconstructed digits side by side')\n",
    "        fig.tight_layout()\n",
    "        fig.subplots_adjust(top=0.80)    \n",
    "        plt.show()        \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mult(tuple):\n",
    "    prod = 1\n",
    "    for i in tuple:\n",
    "        prod *= i\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../convolution-network/mnist/train-images-idx3-ubyte.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1429dc5c8bd7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;31m#set_trace()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[0mmnist_dbn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNIST_DBN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"../convolution-network\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[0mmnist_dbn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mfeature_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-a9b85c10dd1f>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, train_size, n_epoch, batch_size, learning)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mn_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mn_x\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-01d4d4936a8c>\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, num)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mzX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mzy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzy\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[0mmagic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">IIII\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[0mmagic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mny\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\">II\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(filename, mode, compresslevel, encoding, errors, newline)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mgz_mode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"t\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"read\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"write\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mbinary_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGzipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgz_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompresslevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\gzip.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename, mode, compresslevel, fileobj, mtime)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfileobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m             \u001b[0mfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmyfileobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'name'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../convolution-network/mnist/train-images-idx3-ubyte.gz'"
     ]
    }
   ],
   "source": [
    "%run \"RBM.ipynb\"\n",
    "\n",
    "mnist_dbn = None\n",
    "if __name__ == \"__main__\" and '__file__' not in globals():\n",
    "    \n",
    "    np.seterr(all='raise')\n",
    "    plt.close('all')\n",
    "\n",
    "    v = (28,28); h1 = (20,25); h2 = (20,25); h3 = (1000,1)\n",
    "    \n",
    "    #layers = [\n",
    "    #    (mult(h1), None), # (dimension, \"model_file\") of hidden layer 1\n",
    "    #    (mult(h2), None), # (dimension, \"model_file\") of hidden layer 2\n",
    "    #    (mult(h3), None)  # (dimension, \"model_file\") of hidden layer 3\n",
    "    #]\n",
    "\n",
    "    layers = [\n",
    "        (mult(h1), \"trained_models/mnist_rbm.784x500.epochs100\"), # hidden layer 1\n",
    "        (mult(h2), \"trained_models/mnist.dbn.layer3-2.epochs100.500x500\"),\n",
    "        (mult(h3), \"trained_models/mnist.dbn.layer3-3.epochs100.500x1000\")\n",
    "    ]\n",
    "\n",
    "\n",
    "    #set_trace()\n",
    "    mnist_dbn = MNIST_DBN(mult(v), layers, \"../convolution-network\")\n",
    "    mnist_dbn.train(train_size=1000, n_epoch=10, batch_size=10,)\n",
    "\n",
    "    feature_shapes = (v, h1, h2)\n",
    "    mnist_dbn.dbn.show_features(feature_shapes,\"MNIST %d-layer DBN \" % (len(layers)),  14*3)\n",
    "    mnist_dbn.test_reconstruct(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
