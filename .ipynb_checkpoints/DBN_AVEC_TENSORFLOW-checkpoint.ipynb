{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBN AVEC TENSORFLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 46.3%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 53.7%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 44.44%\n",
      "Visual layer (hidden layer) state error ratio: 48.15%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 42.59%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 42.59%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 42.59%\n",
      "Visual layer (hidden layer) state error ratio: 40.74%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 53.7%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 40.74%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 44.44%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 29.63%\n",
      "Visual layer (hidden layer) state error ratio: 46.3%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 53.7%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 44.44%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 29.63%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 44.44%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 40.74%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 40.74%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 37.04%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 40.74%\n",
      "Visual layer (hidden layer) state error ratio: 29.63%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 42.59%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 29.63%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 38.89%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 40.74%\n",
      "Visual layer (hidden layer) state error ratio: 35.19%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 11.11%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 31.48%\n",
      "Visual layer (hidden layer) state error ratio: 33.33%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 27.78%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 11.11%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 24.07%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 18.52%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 12.96%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 22.22%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "Visual layer (hidden layer) state error ratio: 9.26%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 14.81%\n",
      "Visual layer (hidden layer) state error ratio: 20.37%\n",
      "Visual layer (hidden layer) state error ratio: 25.93%\n",
      "Visual layer (hidden layer) state error ratio: 16.67%\n",
      "[0 1 1 0 0 1]\n",
      "0 : loss :  tf.Tensor(0.9059732290690237, shape=(), dtype=float64)\n",
      "1 : loss :  tf.Tensor(0.9046975981981562, shape=(), dtype=float64)\n",
      "2 : loss :  tf.Tensor(0.9034246833863102, shape=(), dtype=float64)\n",
      "3 : loss :  tf.Tensor(0.9021544769782613, shape=(), dtype=float64)\n",
      "4 : loss :  tf.Tensor(0.9008869713499479, shape=(), dtype=float64)\n",
      "5 : loss :  tf.Tensor(0.89962215890831, shape=(), dtype=float64)\n",
      "6 : loss :  tf.Tensor(0.8983600320911341, shape=(), dtype=float64)\n",
      "7 : loss :  tf.Tensor(0.8971005833668957, shape=(), dtype=float64)\n",
      "8 : loss :  tf.Tensor(0.8958438052346046, shape=(), dtype=float64)\n",
      "9 : loss :  tf.Tensor(0.8945896902236485, shape=(), dtype=float64)\n",
      "10 : loss :  tf.Tensor(0.8933382308936402, shape=(), dtype=float64)\n",
      "11 : loss :  tf.Tensor(0.8920894198342645, shape=(), dtype=float64)\n",
      "12 : loss :  tf.Tensor(0.890843249665125, shape=(), dtype=float64)\n",
      "13 : loss :  tf.Tensor(0.889599713035593, shape=(), dtype=float64)\n",
      "14 : loss :  tf.Tensor(0.8883588026246579, shape=(), dtype=float64)\n",
      "15 : loss :  tf.Tensor(0.8871205111407753, shape=(), dtype=float64)\n",
      "16 : loss :  tf.Tensor(0.8858848313217188, shape=(), dtype=float64)\n",
      "17 : loss :  tf.Tensor(0.8846517559344327, shape=(), dtype=float64)\n",
      "18 : loss :  tf.Tensor(0.8834212777748822, shape=(), dtype=float64)\n",
      "19 : loss :  tf.Tensor(0.8821933896679097, shape=(), dtype=float64)\n",
      "20 : loss :  tf.Tensor(0.8809680844670864, shape=(), dtype=float64)\n",
      "21 : loss :  tf.Tensor(0.8797453550545679, shape=(), dtype=float64)\n",
      "22 : loss :  tf.Tensor(0.8785251943409501, shape=(), dtype=float64)\n",
      "23 : loss :  tf.Tensor(0.8773075952651257, shape=(), dtype=float64)\n",
      "24 : loss :  tf.Tensor(0.8760925507941413, shape=(), dtype=float64)\n",
      "25 : loss :  tf.Tensor(0.874880053923055, shape=(), dtype=float64)\n",
      "26 : loss :  tf.Tensor(0.8736700976747953, shape=(), dtype=float64)\n",
      "27 : loss :  tf.Tensor(0.872462675100021, shape=(), dtype=float64)\n",
      "28 : loss :  tf.Tensor(0.8712577792769814, shape=(), dtype=float64)\n",
      "29 : loss :  tf.Tensor(0.8700554033113761, shape=(), dtype=float64)\n",
      "30 : loss :  tf.Tensor(0.8688555403362186, shape=(), dtype=float64)\n",
      "31 : loss :  tf.Tensor(0.8676581835116972, shape=(), dtype=float64)\n",
      "32 : loss :  tf.Tensor(0.8664633260250396, shape=(), dtype=float64)\n",
      "33 : loss :  tf.Tensor(0.8652709610903757, shape=(), dtype=float64)\n",
      "34 : loss :  tf.Tensor(0.8640810819486027, shape=(), dtype=float64)\n",
      "35 : loss :  tf.Tensor(0.8628936818672508, shape=(), dtype=float64)\n",
      "36 : loss :  tf.Tensor(0.8617087541403498, shape=(), dtype=float64)\n",
      "37 : loss :  tf.Tensor(0.8605262920882941, shape=(), dtype=float64)\n",
      "38 : loss :  tf.Tensor(0.8593462890577123, shape=(), dtype=float64)\n",
      "39 : loss :  tf.Tensor(0.8581687384213347, shape=(), dtype=float64)\n",
      "40 : loss :  tf.Tensor(0.8569936335778622, shape=(), dtype=float64)\n",
      "41 : loss :  tf.Tensor(0.8558209679518366, shape=(), dtype=float64)\n",
      "42 : loss :  tf.Tensor(0.8546507349935103, shape=(), dtype=float64)\n",
      "43 : loss :  tf.Tensor(0.8534829281787177, shape=(), dtype=float64)\n",
      "44 : loss :  tf.Tensor(0.8523175410087475, shape=(), dtype=float64)\n",
      "45 : loss :  tf.Tensor(0.8511545670102143, shape=(), dtype=float64)\n",
      "46 : loss :  tf.Tensor(0.8499939997349328, shape=(), dtype=float64)\n",
      "47 : loss :  tf.Tensor(0.8488358327597909, shape=(), dtype=float64)\n",
      "48 : loss :  tf.Tensor(0.847680059686625, shape=(), dtype=float64)\n",
      "49 : loss :  tf.Tensor(0.8465266741420943, shape=(), dtype=float64)\n",
      "50 : loss :  tf.Tensor(0.8453756697775576, shape=(), dtype=float64)\n",
      "51 : loss :  tf.Tensor(0.8442270402689497, shape=(), dtype=float64)\n",
      "52 : loss :  tf.Tensor(0.8430807793166579, shape=(), dtype=float64)\n",
      "53 : loss :  tf.Tensor(0.8419368806454012, shape=(), dtype=float64)\n",
      "54 : loss :  tf.Tensor(0.8407953380041081, shape=(), dtype=float64)\n",
      "55 : loss :  tf.Tensor(0.8396561451657957, shape=(), dtype=float64)\n",
      "56 : loss :  tf.Tensor(0.8385192959274503, shape=(), dtype=float64)\n",
      "57 : loss :  tf.Tensor(0.837384784109907, shape=(), dtype=float64)\n",
      "58 : loss :  tf.Tensor(0.8362526035577317, shape=(), dtype=float64)\n",
      "59 : loss :  tf.Tensor(0.8351227481391027, shape=(), dtype=float64)\n",
      "60 : loss :  tf.Tensor(0.8339952117456927, shape=(), dtype=float64)\n",
      "61 : loss :  tf.Tensor(0.8328699882925529, shape=(), dtype=float64)\n",
      "62 : loss :  tf.Tensor(0.8317470717179958, shape=(), dtype=float64)\n",
      "63 : loss :  tf.Tensor(0.8306264559834796, shape=(), dtype=float64)\n",
      "64 : loss :  tf.Tensor(0.8295081350734944, shape=(), dtype=float64)\n",
      "65 : loss :  tf.Tensor(0.8283921029954459, shape=(), dtype=float64)\n",
      "66 : loss :  tf.Tensor(0.8272783537795431, shape=(), dtype=float64)\n",
      "67 : loss :  tf.Tensor(0.8261668814786851, shape=(), dtype=float64)\n",
      "68 : loss :  tf.Tensor(0.8250576801683478, shape=(), dtype=float64)\n",
      "69 : loss :  tf.Tensor(0.8239507439464717, shape=(), dtype=float64)\n",
      "70 : loss :  tf.Tensor(0.8228460669333525, shape=(), dtype=float64)\n",
      "71 : loss :  tf.Tensor(0.821743643271528, shape=(), dtype=float64)\n",
      "72 : loss :  tf.Tensor(0.8206434671256695, shape=(), dtype=float64)\n",
      "73 : loss :  tf.Tensor(0.8195455326824722, shape=(), dtype=float64)\n",
      "74 : loss :  tf.Tensor(0.8184498341505453, shape=(), dtype=float64)\n",
      "75 : loss :  tf.Tensor(0.8173563657603042, shape=(), dtype=float64)\n",
      "76 : loss :  tf.Tensor(0.8162651217638633, shape=(), dtype=float64)\n",
      "77 : loss :  tf.Tensor(0.8151760964349284, shape=(), dtype=float64)\n",
      "78 : loss :  tf.Tensor(0.8140892840686894, shape=(), dtype=float64)\n",
      "79 : loss :  tf.Tensor(0.8130046789817156, shape=(), dtype=float64)\n",
      "80 : loss :  tf.Tensor(0.8119222755118488, shape=(), dtype=float64)\n",
      "81 : loss :  tf.Tensor(0.8108420680181001, shape=(), dtype=float64)\n",
      "82 : loss :  tf.Tensor(0.8097640508805442, shape=(), dtype=float64)\n",
      "83 : loss :  tf.Tensor(0.808688218500216, shape=(), dtype=float64)\n",
      "84 : loss :  tf.Tensor(0.8076145652990081, shape=(), dtype=float64)\n",
      "85 : loss :  tf.Tensor(0.8065430857195673, shape=(), dtype=float64)\n",
      "86 : loss :  tf.Tensor(0.8054737742251936, shape=(), dtype=float64)\n",
      "87 : loss :  tf.Tensor(0.8044066252997366, shape=(), dtype=float64)\n",
      "88 : loss :  tf.Tensor(0.8033416334474971, shape=(), dtype=float64)\n",
      "89 : loss :  tf.Tensor(0.802278793193125, shape=(), dtype=float64)\n",
      "90 : loss :  tf.Tensor(0.8012180990815205, shape=(), dtype=float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91 : loss :  tf.Tensor(0.800159545677734, shape=(), dtype=float64)\n",
      "92 : loss :  tf.Tensor(0.7991031275668669, shape=(), dtype=float64)\n",
      "93 : loss :  tf.Tensor(0.798048839353975, shape=(), dtype=float64)\n",
      "94 : loss :  tf.Tensor(0.7969966756639687, shape=(), dtype=float64)\n",
      "95 : loss :  tf.Tensor(0.7959466311415182, shape=(), dtype=float64)\n",
      "96 : loss :  tf.Tensor(0.7948987004509539, shape=(), dtype=float64)\n",
      "97 : loss :  tf.Tensor(0.7938528782761731, shape=(), dtype=float64)\n",
      "98 : loss :  tf.Tensor(0.7928091593205431, shape=(), dtype=float64)\n",
      "99 : loss :  tf.Tensor(0.791767538306805, shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def DBN(epoch, test_data, rbm_list,  lr=0.001):\n",
    "    # Compilation du DBN\n",
    "    \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RBM1_w = tf.Variable(tf.convert_to_tensor(rbm_list[0].weights))    \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RBM1_vb = tf.Variable(tf.convert_to_tensor(rbm_list[0].bias_a))     \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RBM1_hb = tf.Variable(tf.convert_to_tensor(rbm_list[0].bias_b))     \n",
    "    \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RBM1to2_w = tf.Variable(tf.random.normal([6, 6],dtype=tf.float64))  \n",
    "\n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RMB2_w = tf.Variable(tf.convert_to_tensor(rbm_list[1].weights))     \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RBM2_vb = tf.Variable(tf.convert_to_tensor(rbm_list[1].bias_a))     \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    RBM2_hb = tf.Variable(tf.convert_to_tensor(rbm_list[1].bias_b))     \n",
    "\n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    BP_w = tf.Variable(tf.random.normal([6,6],dtype=tf.float64))        \n",
    "    # Convertir les données en type variable pour faciliter le  \"gradient tracking\"\n",
    "    BP_b = tf.Variable(tf.random.normal([6],dtype=tf.float64))          \n",
    "\n",
    "    test_data = tf.Variable(tf.convert_to_tensor(test_data,dtype=tf.float64))\n",
    "\n",
    "    # Affiner le nombre des itérations\n",
    "    for step in range(epoch):\n",
    "        # Calculaler le \"forward propagation\" du batch courant\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Forward propagation\n",
    "            # Première couche : v-h\n",
    "            out1 = tf.nn.sigmoid(RBM1_hb + test_data @ RBM1_w)\n",
    "            # 2ème couche : h-v\n",
    "            out2 = tf.nn.sigmoid(RBM2_vb + out1 @ RBM1to2_w)\n",
    "            # 3ème couche : v-h\n",
    "            out3 = tf.nn.sigmoid(RBM2_hb + out2 @ RMB2_w)\n",
    "            out = tf.nn.relu(BP_b + out3 @ BP_w)\n",
    "            # Backpropagation\n",
    "            # Calculer la fonction de perte : loss function\n",
    "            loss = tf.reduce_mean(tf.square(test_data - out))   # Mean square error loss function\n",
    "            # Mise-à-jour des gradients (Manual gradient update parameters)\n",
    "            grads = tape.gradient(loss, [RBM1_w, RBM1_vb, RBM1_hb,\n",
    "                                         RBM1to2_w,\n",
    "                                         RMB2_w, RBM2_vb, RBM2_hb,\n",
    "                                         BP_b,BP_w])\n",
    "            # Mise-à-jour des paramètres\n",
    "            RBM1_w.assign_sub(lr * grads[0])\n",
    "            # RBM1_vb = RBM1_vb - lr * grads[1]\n",
    "            RBM1_hb.assign_sub(lr * grads[2])\n",
    "            RBM1to2_w.assign_sub(lr * grads[3])\n",
    "            RMB2_w.assign_sub(lr * grads[4])\n",
    "            RBM2_vb.assign_sub(lr * grads[5])\n",
    "            RBM2_hb.assign_sub(lr * grads[6])\n",
    "            BP_b.assign_sub(lr * grads[7])\n",
    "            BP_w.assign_sub(lr * grads[8])\n",
    "\n",
    "            print(step,\": loss : \", loss)\n",
    "\n",
    "class RBM:\n",
    "    def __init__(self, n_visible, n_hidden):\n",
    "        self.n_visible = n_visible          # Nombre des noeuds de la couche visible\n",
    "        self.n_hidden = n_hidden            # Nombre des noeuds de la couche cachée\n",
    "        self.bias_a = np.zeros(self.n_visible)  # Décalage de la couche visible\n",
    "        self.bias_b = np.zeros(self.n_hidden)  # Décalage de la couche cachée\n",
    "        self.weights = np.random.normal(0, 0.01, size=(self.n_visible, self.n_hidden))  # Connection weight w\n",
    "        self.n_sample = None\n",
    "\n",
    "    def encode(self, v):\n",
    "        # Encodage (calculer la probabilité conditionnelle : p(h=1|v))\n",
    "        return sigmoid(self.bias_b + v @ self.weights)\n",
    "\n",
    "    def decode(self, h):\n",
    "        # Décodage (reconstruction): (calculer la probabilité conditionnelle : p(v=1|h)\n",
    "        return sigmoid(self.bias_a + h @ self.weights.T)\n",
    "\n",
    "    # gibbs sampling (Echantillonnage): retourner les valeurs de v et h après \"max_cd\" sampling\n",
    "    def gibbs_sample(self, v0, max_cd):\n",
    "        v = v0\n",
    "        for _ in range(max_cd):\n",
    "            # 1er Echantillonnage : each hidden layer neuron according to the input sample. Binomial distribution sampling to determine whether the neuron is activated\n",
    "            ph = self.encode(v)\n",
    "            h = np.random.binomial(1, ph, (self.n_sample, self.n_hidden))\n",
    "            # Sample each visual layer neuron according to the value of the hidden layer neuron after sampling\n",
    "            pv = self.decode(h)\n",
    "            v = np.random.binomial(1, pv, (self.n_sample, self.n_visible))\n",
    "        return v\n",
    "\n",
    "    # According to the visible layer value obtained by Gibbs sampling (decoding or reconstruction), update the parameters\n",
    "    def update(self, v0, v_cd, eta):\n",
    "        ph = self.encode(v0)\n",
    "        ph_cd = self.encode(v_cd)\n",
    "        self.weights += eta * (v0.T @ ph - v_cd.T @ ph)  # Update the connection weight parameter\n",
    "        self.bias_b += eta * np.mean(ph - ph_cd, axis=0)  # Update hidden layer offset b\n",
    "        self.bias_a += eta * np.mean(v0 - v_cd, axis=0)  # Update the visible layer offset a\n",
    "        return\n",
    "\n",
    "    # Training function Update parameters using contrast divergence algorithm\n",
    "    def fit(self, data, max_step, max_cd=2, eta=0.1):\n",
    "        # data training data set\n",
    "        # max_cd Sampling steps\n",
    "        # max_step: Maximum number of iterations iter\n",
    "        # eta: learning rate\n",
    "        assert data.shape[1] == self.n_visible, \"The input data dimension is not equal to the number of neurons in the visual layer\"\n",
    "        self.n_sample = data.shape[0]\n",
    "\n",
    "        for i in range(max_step):\n",
    "            v_cd = self.gibbs_sample(data, max_cd)\n",
    "            self.update(data, v_cd, eta)\n",
    "            error = np.sum((data - v_cd) ** 2) / self.n_sample / self.n_visible * 100\n",
    "            if i == (max_step-1):  # Compare the reconstructed sample with the original sample to calculate the error\n",
    "                print(\"Visual layer (hidden layer) state error ratio: {0}%\".format(round(error, 2)))\n",
    "\n",
    "    # Forecast\n",
    "    def predict(self, v):\n",
    "        # Input training data, predict hidden layer output\n",
    "        ph = self.encode(v)[0]\n",
    "        states = ph >= np.random.rand(len(ph))\n",
    "        return states.astype(int)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Number of iterations\n",
    "    iter = 100\n",
    "    # Learning rate\n",
    "    lr = 0.001\n",
    "    # N represents the number of RBM layers that make up the DBN\n",
    "    N = 2\n",
    "\n",
    "    # Create multiple RBM layers\n",
    "    rbm_model_list = []\n",
    "    # Used for the connection weight of two RBMs, h-v\n",
    "    for i in range(N):\n",
    "        rbm_model_list.append(RBM(n_visible=6, n_hidden=6))\n",
    "\n",
    "    # Training set data\n",
    "    V = np.array([[1, 1, 1, 0, 0, 0], [1, 0, 1, 0, 0, 0], [1, 1, 1, 0, 0, 0],\n",
    "                  [0, 0, 1, 1, 1, 0], [0, 0, 1, 1, 0, 0], [0, 0, 1, 1, 1, 0],\n",
    "                  [1, 0, 0, 1, 1, 0], [0, 0, 0, 1, 0, 0], [0, 0, 1, 0, 1, 0]])\n",
    "\n",
    "    # Train the parameters of each RBM layer separately\n",
    "    for epoch in range(iter):   # Number of iterations\n",
    "        for i in range(N):      # Each iteration train each RBM layer separately\n",
    "            rbm_model_list[i].fit(V, max_step=iter, max_cd=1, eta=lr)\n",
    "\n",
    "    # Connect two layers of RBM in series for prediction\n",
    "    user = np.array([[1,0,0,1,0,0]])\n",
    "    temp = rbm_model_list[0].predict(user)\n",
    "    out = rbm_model_list[1].predict([temp])\n",
    "    print(out)\n",
    "\n",
    "    DBN(iter,V,rbm_model_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
